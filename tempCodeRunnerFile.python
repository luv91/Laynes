import torch
import torch.nn as nn

class XLNetSMF(nn.Module):
    def __init__(self, feature_dims, embedding_dim=256):
        super().__init__()
        
        # 1. Feature Embedding Layers
        self.embedding_layers = nn.ModuleDict({
            # Categorical embeddings
            'city_id': nn.Embedding(feature_dims['city_id'], embedding_dim),
            'hotel_country': nn.Embedding(feature_dims['hotel_country'], embedding_dim),
            'booker_country': nn.Embedding(feature_dims['booker_country'], embedding_dim),
            'device_class': nn.Embedding(feature_dims['device_class'], embedding_dim),
            'affiliate_id': nn.Embedding(feature_dims['affiliate_id'], embedding_dim),
            
            # Temporal embeddings
            'day_of_week': nn.Embedding(7, embedding_dim),
            'month': nn.Embedding(12, embedding_dim),
            'season': nn.Embedding(4, embedding_dim),
            
            # Numerical projections
            'numerical': nn.Linear(1, embedding_dim)
        })
        
        # 2. Reservation Embedding Generation
        self.reservation_fc = nn.Sequential(
            nn.Linear(embedding_dim * len(feature_dims), embedding_dim),
            nn.LayerNorm(embedding_dim),
            nn.ReLU()
        )
        
        # 3. XLNet Transformer Blocks
        self.transformer_blocks = nn.TransformerEncoder(
            encoder_layer=nn.TransformerEncoderLayer(
                d_model=embedding_dim,
                nhead=8,
                dim_feedforward=embedding_dim * 4
            ),
            num_layers=6
        )
        
        # 4. Trip Embedding Generation
        self.trip_fc = nn.Linear(embedding_dim, embedding_dim)
        
        # 5. Matrix Factorization Head
        self.mf_head = nn.Linear(embedding_dim, feature_dims['city_id'])
        
    def forward(self, batch):
        # 1. Process each reservation in the sequence
        reservation_embeddings = []
        for reservation in batch['sequence']:
            # Embed all features
            feature_embeddings = []
            for feature_name, value in reservation.items():
                if feature_name in ['stay_length', 'days_since_last_booking']:
                    emb = self.embedding_layers['numerical'](value.unsqueeze(-1))
                else:
                    emb = self.embedding_layers[feature_name](value)
                feature_embeddings.append(emb)
            
            # Concatenate and project to reservation embedding
            concat_features = torch.cat(feature_embeddings, dim=-1)
            reservation_emb = self.reservation_fc(concat_features)
            reservation_embeddings.append(reservation_emb)
        
        # 2. Create sequence of reservation embeddings
        sequence = torch.stack(reservation_embeddings, dim=1)
        
        # 3. Pass through transformer blocks
        transformer_output = self.transformer_blocks(sequence)
        
        # 4. Generate trip embedding from transformer output
        trip_embedding = self.trip_fc(transformer_output[:, -1, :])  # Use last position
        
        # 5. Generate city scores through matrix factorization
        city_scores = self.mf_head(trip_embedding)
        
        # 6. Apply softmax for probabilities
        return torch.softmax(city_scores, dim=-1)
    
import torch
import torch.nn as nn
import numpy as np

# Define feature dimensions
feature_dims = {
    'city_id': 40000,  # Total number of unique cities
    'hotel_country': 100,  # Total number of unique hotel countries
    'booker_country': 100,  # Total number of unique booker countries
    'device_class': 3,  # e.g., mobile, desktop, tablet
    'affiliate_id': 1000,  # Total number of unique affiliates
}

# Create sample batch data
def create_sample_batch(batch_size=2, seq_length=3):
    """
    Creates a sample batch of trip sequences
    batch_size: number of trips in batch
    seq_length: number of reservations per trip
    """
    batch = {
        'sequence': []
    }
    
    for _ in range(batch_size):
        sequence = []
        for _ in range(seq_length):
            reservation = {
                # Categorical features
                'city_id': torch.randint(0, feature_dims['city_id'], (1,)),
                'hotel_country': torch.randint(0, feature_dims['hotel_country'], (1,)),
                'booker_country': torch.randint(0, feature_dims['booker_country'], (1,)),
                'device_class': torch.randint(0, feature_dims['device_class'], (1,)),
                'affiliate_id': torch.randint(0, feature_dims['affiliate_id'], (1,)),
                
                # Temporal features
                'day_of_week': torch.randint(0, 7, (1,)),
                'month': torch.randint(0, 12, (1,)),
                'season': torch.randint(0, 4, (1,)),
                
                # Numerical features
                'stay_length': torch.tensor([np.random.randint(1, 10)]).float(),
                'days_since_last_booking': torch.tensor([np.random.randint(0, 30)]).float()
            }
            sequence.append(reservation)
        batch['sequence'].append(sequence)
    
    return batch

# Example usage
def main():
    # Initialize model
    model = XLNetSMF(feature_dims)
    
    # Create sample batch
    batch = create_sample_batch(batch_size=2, seq_length=3)
    
    # Get predictions
    with torch.no_grad():
        predictions = model(batch)
    
    # Print sample results
    print("\nBatch shape:", predictions.shape)  # Should be [batch_size, num_cities]
    print("\nTop 5 predicted cities for first trip:")
    top_cities = torch.topk(predictions[0], k=5)
    for i, (prob, city_idx) in enumerate(zip(top_cities.values, top_cities.indices)):
        print(f"Rank {i+1}: City ID {city_idx.item()} (Probability: {prob:.4f})")

    return predictions

# Run example
if __name__ == "__main__":
    # Create a more detailed example with actual trip data
    example_trip = {
        'sequence': [[
            # First reservation (Paris)
            {
                'city_id': torch.tensor([8652]),
                'hotel_country': torch.tensor([33]),  # France
                'booker_country': torch.tensor([33]),  # France
                'device_class': torch.tensor([1]),    # mobile
                'affiliate_id': torch.tensor([100]),
                'day_of_week': torch.tensor([1]),     # Monday
                'month': torch.tensor([6]),           # June
                'season': torch.tensor([2]),          # Summer
                'stay_length': torch.tensor([2.0]),
                'days_since_last_booking': torch.tensor([0.0])
            },
            # Second reservation (Lyon)
            {
                'city_id': torch.tensor([8655]),
                'hotel_country': torch.tensor([33]),  # France
                'booker_country': torch.tensor([33]),  # France
                'device_class': torch.tensor([1]),    # mobile
                'affiliate_id': torch.tensor([100]),
                'day_of_week': torch.tensor([3]),     # Wednesday
                'month': torch.tensor([6]),           # June
                'season': torch.tensor([2]),          # Summer
                'stay_length': torch.tensor([3.0]),
                'days_since_last_booking': torch.tensor([2.0])
            }
        ]]
    }
    
    # Initialize model
    model = XLNetSMF(feature_dims)
    
    # Get predictions
    with torch.no_grad():
        predictions = model(example_trip)
    
    print("\nPredictions for Paris -> Lyon sequence:")
    print("Model suggests these cities as the next destination:")
    top_cities = torch.topk(predictions[0], k=5)
    for i, (prob, city_idx) in enumerate(zip(top_cities.values, top_cities.indices)):
        print(f"Rank {i+1}: City ID {city_idx.item()} (Probability: {prob:.4f})")
    
    # You would typically map these city_ids back to actual city names
    # city_id_to_name = {8652: "Paris", 8655: "Lyon", 8658: "Nice", ...}